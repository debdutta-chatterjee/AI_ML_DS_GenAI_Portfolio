{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd2db35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debdutta Chatterjee\\AppData\\Local\\Temp\\ipykernel_30820\\4106985964.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop_duplicates(inplace=True)\n",
      "C:\\Users\\Debdutta Chatterjee\\AppData\\Local\\Temp\\ipykernel_30820\\4106985964.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].apply(remove_tags)\n",
      "C:\\Users\\Debdutta Chatterjee\\AppData\\Local\\Temp\\ipykernel_30820\\4106985964.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].apply(lambda x:x.lower())\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "temp_df = pd.read_csv('IMDB Dataset.csv')\n",
    "df = temp_df.iloc[:10000]\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "import re\n",
    "def remove_tags(raw_text):\n",
    "    cleaned_text = re.sub(re.compile('<.*?>'), '', raw_text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "df['review'] = df['review'].apply(remove_tags)\n",
    "df['review'] = df['review'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db04b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Debdutta\n",
      "[nltk_data]     Chatterjee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "!python -m nltk.downloader stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abfb9ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debdutta Chatterjee\\AppData\\Local\\Temp\\ipykernel_30820\\2984342538.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw_list = stopwords.words('english')\n",
    "\n",
    "df['review'] = df['review'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "088d0ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Debdutta\n",
      "[nltk_data]     Chatterjee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Debdutta\n",
      "[nltk_data]     Chatterjee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m nltk.downloader punkt stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fc8849d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Debdutta\n",
      "[nltk_data]     Chatterjee/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Debdutta\n",
      "[nltk_data]     Chatterjee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m nltk.downloader punkt_tab stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4298c26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Debdutta\n",
      "[nltk_data]     Chatterjee\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Debdutta\n",
      "[nltk_data]     Chatterjee\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences processed: 106789\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Force download to a known location\n",
    "nltk_data_dir = os.path.join(os.path.expanduser('~'), 'nltk_data')\n",
    "nltk.download('punkt_tab', download_dir=nltk_data_dir, quiet=False)\n",
    "nltk.download('stopwords', download_dir=nltk_data_dir, quiet=False)\n",
    "\n",
    "# Add to path\n",
    "if nltk_data_dir not in nltk.data.path:\n",
    "    nltk.data.path.insert(0, nltk_data_dir)\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "# Build sentence list safely\n",
    "story = []\n",
    "for doc in df['review'].astype(str):\n",
    "    try:\n",
    "        raw_sent = sent_tokenize(doc)\n",
    "        for sent in raw_sent:\n",
    "            story.append(simple_preprocess(sent))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing doc: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Total sentences processed: {len(story)}\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57f32387",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "574a2b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5853793, 6189340)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(story, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "771d03e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31807"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df67dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc.split() if word in model.wv.index_to_key]\n",
    "    return np.mean(model.wv[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c59da04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16544573,  0.06248593,  0.07879287,  0.06458876,  0.2350135 ,\n",
       "       -0.56824535,  0.30062285,  0.81751716, -0.21189125, -0.32854733,\n",
       "       -0.0718242 , -0.44317797, -0.09458418,  0.0155193 , -0.00601026,\n",
       "       -0.28963295,  0.0835732 , -0.3351056 , -0.04991894, -0.7852858 ,\n",
       "        0.04017147,  0.29336888,  0.06064676, -0.19309776,  0.03956757,\n",
       "       -0.04209666, -0.0933666 , -0.14241022, -0.50299096,  0.06092562,\n",
       "        0.37817824, -0.20898075,  0.18556409, -0.41904026, -0.14416844,\n",
       "        0.5730027 ,  0.19646838, -0.39489087, -0.1489744 , -0.62464476,\n",
       "        0.0031885 , -0.21055278,  0.03750465,  0.02718301,  0.39106292,\n",
       "       -0.20230947, -0.2775816 , -0.2619167 , -0.01908296,  0.21231437,\n",
       "       -0.01978374, -0.36232463, -0.28523326, -0.17943223, -0.07775246,\n",
       "        0.09776937,  0.17392775,  0.0123529 , -0.37073058,  0.19028771,\n",
       "        0.13549542,  0.08041345,  0.27044302,  0.09804777, -0.47222704,\n",
       "        0.44802266,  0.01649114,  0.13086428, -0.43127424,  0.36320296,\n",
       "       -0.22240202,  0.1232234 ,  0.5562782 , -0.06441704,  0.44556966,\n",
       "       -0.16829814, -0.04952818, -0.12390035, -0.5697954 ,  0.1245627 ,\n",
       "       -0.26769856, -0.16774093, -0.43463787,  0.64998287, -0.04429932,\n",
       "       -0.09378585,  0.10726894,  0.30210993,  0.30724245, -0.05296344,\n",
       "        0.10472977,  0.2806974 ,  0.14939758,  0.1944566 ,  0.8229133 ,\n",
       "        0.21850434,  0.25154278, -0.35835835,  0.12159143, -0.24719717],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vector(df['review'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78983bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9987/9987 [02:53<00:00, 57.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "X = []\n",
    "for doc in tqdm(df['review'].values):\n",
    "    X.append(document_vector(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e94e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dab7b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98a8b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f2247fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44dacccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7587587587587588"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
