{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca1904f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.\\n    ',\n",
       " '\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.\\n    ',\n",
       " '\\n    Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.\\n    ']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "    \n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
    "    and improve from experience without being explicitly programmed. There are three main \n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "    \n",
    "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
    "    These networks are inspired by the human brain and consist of layers of interconnected \n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "    \n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "sample_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "333f09a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document create in : C:\\Users\\Debdutta Chatterjee\\AppData\\Local\\Temp\\tmpuiyh4tbc\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "temp_dir=tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(sample_docs):\n",
    "    with open(f\"{temp_dir}/doc_{i}.txt\",\"w\") as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(f\"Sample document create in : {temp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4228d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "temp_dir=tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(sample_docs):\n",
    "    with open(f\"doc_{i}.txt\",\"w\") as f:\n",
    "        f.write(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1452afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader,TextLoader\n",
    "\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    path ='C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t',\n",
    "    glob ='*.txt',\n",
    "    loader_cls =TextLoader,\n",
    "    loader_kwargs={'encoding':'utf-8'}\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e81b6e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size =100,\n",
    "    chunk_overlap =10\n",
    ")\n",
    "docs = loader.load()\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f375bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Debdutta Chatterjee\\Work\\Project\\Python\\AI_ML_DS_GenAI_Portfolio\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings  = GoogleGenerativeAIEmbeddings(\n",
    "    model = 'models/text-embedding-004',\n",
    "    google_api_key = 'AIzaSyCtTc-rIeCTfJsfIMHFqnSIjhPbSJpy5Yc'\n",
    ")\n",
    "\n",
    "em = embeddings.embed_query('Hi')\n",
    "len(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15641aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd3f9ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x23aa8f10ce0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vs = Chroma.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory='./chrom_db',\n",
    "    collection_name='rag_demo'\n",
    ")\n",
    "\n",
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "088b209d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs.similarity_search('Machine learning',k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f25422ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       "  0.18090315163135529),\n",
       " (Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       "  0.18090315163135529),\n",
       " (Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       "  0.18090315163135529),\n",
       " (Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)'),\n",
       "  0.23174500465393066),\n",
       " (Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)'),\n",
       "  0.23174500465393066)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs.similarity_search_with_score('Deep learning',k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72b39e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--469d9453-04aa-4134-9b96-2c7880ce3ac4-0', usage_metadata={'input_tokens': 1, 'output_tokens': 10, 'total_tokens': 11, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyCtTc-rIeCTfJsfIMHFqnSIjhPbSJpy5Yc\"\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "                model='gemini-2.0-flash',\n",
    "                google_api_key=\"AIzaSyCtTc-rIeCTfJsfIMHFqnSIjhPbSJpy5Yc\",\n",
    "                temperature=0,\n",
    "                max_output_tokens=1000\n",
    "            )\n",
    "\n",
    "model.invoke('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc796993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000023AA8F10CE0>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vs.as_retriever(search_type='similarity',search_kwargs={'k':3})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e843efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt=\"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    \n",
    "    ('system',system_prompt),\n",
    "    ('human','{input}')\n",
    "    \n",
    "])\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ae4a2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_output_tokens=1000, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000023AD2E1D700>, default_metadata=(), model_kwargs={})\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "doc_chain =create_stuff_documents_chain(model,prompt)\n",
    "doc_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47a635a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000023AA8F10CE0>, search_kwargs={'k': 3}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_output_tokens=1000, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000023AD2E1D700>, default_metadata=(), model_kwargs={})\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import  create_retrieval_chain\n",
    "\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever,\n",
    "    doc_chain\n",
    ")\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "802d34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=rag_chain.invoke({\"input\":\"What is Deep LEarning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b000838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is Deep LEarning',\n",
       " 'context': [Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks.'),\n",
       "  Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks.'),\n",
       "  Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks.')],\n",
       " 'answer': 'Deep learning is a subset of machine learning. It is based on artificial neural networks.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4063618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LCEl\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Use the following context to answer the question. \n",
    "If you don't know the answer based on the context, say you don't know.\n",
    "Provide specific details from the context to support your answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "718ffb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000023AA8F10CE0>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f92d2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(d.page_content for d in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df6e0e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000023AA8F10CE0>, search_kwargs={'k': 3})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following context to answer the question. \\nIf you don't know the answer based on the context, say you don't know.\\nProvide specific details from the context to support your answer.\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"), additional_kwargs={})])\n",
       "| ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_output_tokens=1000, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000023AD2E1D700>, default_metadata=(), model_kwargs={})\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain =(\n",
    "{\n",
    "    'context':retriever|format_docs,\n",
    "    'question': RunnablePassthrough()\n",
    "}\n",
    "|prompt\n",
    "|model\n",
    "|StrOutputParser()\n",
    ")\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0eba15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning is a subset of machine learning based on artificial neural networks.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=rag_chain.invoke(\"What is Deep Learning\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30c0d196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debdutta Chatterjee\\AppData\\Local\\Temp\\ipykernel_12988\\3631917653.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retriever.get_relevant_documents('deep learning')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents('deep learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed45742e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['968f4954-f0a3-4e3f-a606-774e70815697']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "d1 = Document(\n",
    "    page_content = 'DL is a fraud',\n",
    "    metadata = {'source':'Fake source'}\n",
    ")\n",
    "\n",
    "vs.add_documents([d1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0e33bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vs._collection\n",
    "client.delete(ids =['968f4954-f0a3-4e3f-a606-774e70815697'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3513bfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b7b1bcbc-7392-48eb-94c4-26f96c25d9d7']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "d1 = Document(\n",
    "    page_content = 'MDD is a fraud',\n",
    "    metadata = {'source':'Fake source'}\n",
    ")\n",
    "\n",
    "vs.add_documents([d1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0e43e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context states \"MDD is a fraud\".'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke('what is MDD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff1175d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe728446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000023AA8D43420>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Given a chat history and the latest user question \\nwhich might reference context in the chat history, formulate a standalone question \\nwhich can be understood without the chat history. Do NOT answer the question, \\njust reformulate it if needed and otherwise return it as is.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \n",
    "which might reference context in the chat history, formulate a standalone question \n",
    "which can be understood without the chat history. Do NOT answer the question, \n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "\n",
    "prompt  = ChatPromptTemplate.from_messages([\n",
    "    ('system',contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder('chat_history'),\n",
    "    ('human','{input}')\n",
    "])\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68162931",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = create_history_aware_retriever(\n",
    "    model,retriever,prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08855455",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", qa_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96853dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversational RAG chain created!\n"
     ]
    }
   ],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(model, qa_prompt)\n",
    "\n",
    "# Create conversational RAG chain\n",
    "conversational_rag_chain = create_retrieval_chain(\n",
    "    retriever, \n",
    "    question_answer_chain\n",
    ")\n",
    "print(\"Conversational RAG chain created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c28056cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "result1 =conversational_rag_chain.invoke({\n",
    "    'chat_history':history,\n",
    "    'input':\"What is machine learning?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6824c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.extend([\n",
    "    HumanMessage(content=\"What is machine learning\"),\n",
    "    AIMessage(content=result1['answer'])\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
