{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca1904f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.\\n    ',\n",
       " '\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.\\n    ',\n",
       " '\\n    Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.\\n    ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "    \n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
    "    and improve from experience without being explicitly programmed. There are three main \n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "    \n",
    "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
    "    These networks are inspired by the human brain and consist of layers of interconnected \n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "    \n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "sample_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "333f09a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document create in : C:\\Users\\Debdutta Chatterjee\\AppData\\Local\\Temp\\tmp4u0cq6pg\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "temp_dir=tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(sample_docs):\n",
    "    with open(f\"{temp_dir}/doc_{i}.txt\",\"w\") as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(f\"Sample document create in : {temp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4228d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "temp_dir=tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(sample_docs):\n",
    "    with open(f\"doc_{i}.txt\",\"w\") as f:\n",
    "        f.write(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1452afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader,TextLoader\n",
    "\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    path ='C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t',\n",
    "    glob ='*.txt',\n",
    "    loader_cls =TextLoader,\n",
    "    loader_kwargs={'encoding':'utf-8'}\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e81b6e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size =100,\n",
    "    chunk_overlap =10\n",
    ")\n",
    "docs = loader.load()\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f375bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings  = GoogleGenerativeAIEmbeddings(\n",
    "    model = 'models/text-embedding-004',\n",
    "    google_api_key = 'AIzaSyCtTc-rIeCTfJsfIMHFqnSIjhPbSJpy5Yc'\n",
    ")\n",
    "\n",
    "em = embeddings.embed_query('Hi')\n",
    "len(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15641aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd3f9ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x2945f522660>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vs = Chroma.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory='./chrom_db',\n",
    "    collection_name='rag_demo'\n",
    ")\n",
    "\n",
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "088b209d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs.similarity_search('Machine learning',k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f25422ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       "  0.18090315163135529),\n",
       " (Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       "  0.18090315163135529),\n",
       " (Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)'),\n",
       "  0.23174500465393066),\n",
       " (Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)'),\n",
       "  0.23174500465393066),\n",
       " (Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly'),\n",
       "  0.2812560796737671)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs.similarity_search_with_score('Deep learning',k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72b39e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--0500295d-e841-48aa-902e-ecb0fcf36fe3-0', usage_metadata={'input_tokens': 1, 'output_tokens': 10, 'total_tokens': 11, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyCtTc-rIeCTfJsfIMHFqnSIjhPbSJpy5Yc\"\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "                model='gemini-2.0-flash',\n",
    "                google_api_key=\"AIzaSyCtTc-rIeCTfJsfIMHFqnSIjhPbSJpy5Yc\",\n",
    "                temperature=0,\n",
    "                max_output_tokens=1000\n",
    "            )\n",
    "\n",
    "model.invoke('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc796993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000002945F522660>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vs.as_retriever(search_type='similarity',search_kwargs={'k':3})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e843efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt=\"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    \n",
    "    ('system',system_prompt),\n",
    "    ('human','{input}')\n",
    "    \n",
    "])\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ae4a2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_output_tokens=1000, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000294632AFC80>, default_metadata=(), model_kwargs={})\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "doc_chain =create_stuff_documents_chain(model,prompt)\n",
    "doc_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47a635a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000002945F522660>, search_kwargs={'k': 3}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_output_tokens=1000, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000294632AFC80>, default_metadata=(), model_kwargs={})\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import  create_retrieval_chain\n",
    "\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever,\n",
    "    doc_chain\n",
    ")\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "802d34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=rag_chain.invoke({\"input\":\"What is Deep LEarning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b000838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is Deep LEarning',\n",
       " 'context': [Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks.'),\n",
       "  Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks.'),\n",
       "  Document(metadata={'source': 'C:\\\\Users\\\\Debdutta Chatterjee\\\\AppData\\\\Local\\\\Temp\\\\tmpmi9w_c2t\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks')],\n",
       " 'answer': 'Deep learning is a subset of machine learning. It is based on artificial neural networks.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
