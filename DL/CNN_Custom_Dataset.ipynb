{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6ce276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "  0 21.8M    0 50106    0     0  15756      0  0:24:15  0:00:03  0:24:12 52910\n",
      "  2 21.8M    2  475k    0     0   116k      0  0:03:12  0:00:04  0:03:08  255k\n",
      "  7 21.8M    7 1598k    0     0   313k      0  0:01:11  0:00:05  0:01:06  558k\n",
      "  9 21.8M    9 2144k    0     0   350k      0  0:01:03  0:00:06  0:00:57  553k\n",
      " 12 21.8M   12 2704k    0     0   381k      0  0:00:58  0:00:07  0:00:51  556k\n",
      " 14 21.8M   14 3312k    0     0   408k      0  0:00:54  0:00:08  0:00:46  661k\n",
      " 17 21.8M   17 3856k    0     0   419k      0  0:00:53  0:00:09  0:00:44  661k\n",
      " 19 21.8M   19 4427k    0     0   430k      0  0:00:52  0:00:10  0:00:42  544k\n",
      " 21 21.8M   21 4739k    0     0   426k      0  0:00:52  0:00:11  0:00:41  517k\n",
      " 22 21.8M   22 5105k    0     0   419k      0  0:00:53  0:00:12  0:00:41  473k\n",
      " 24 21.8M   24 5592k    0     0   427k      0  0:00:52  0:00:13  0:00:39  458k\n",
      " 27 21.8M   27 6138k    0     0   435k      0  0:00:51  0:00:14  0:00:37  466k\n",
      " 30 21.8M   30 6881k    0     0   456k      0  0:00:49  0:00:15  0:00:34  511k\n",
      " 34 21.8M   34 7620k    0     0   467k      0  0:00:47  0:00:16  0:00:31  557k\n",
      " 35 21.8M   35 8031k    0     0   459k      0  0:00:48  0:00:17  0:00:31  549k\n",
      " 37 21.8M   37 8384k    0     0   461k      0  0:00:48  0:00:18  0:00:30  551k\n",
      " 39 21.8M   39 8772k    0     0   459k      0  0:00:48  0:00:19  0:00:29  527k\n",
      " 41 21.8M   41 9362k    0     0   465k      0  0:00:48  0:00:20  0:00:28  493k\n",
      " 43 21.8M   43 9847k    0     0   457k      0  0:00:48  0:00:21  0:00:27  425k\n",
      " 45 21.8M   45  9.9M    0     0   455k      0  0:00:49  0:00:22  0:00:27  440k\n",
      " 46 21.8M   46 10.1M    0     0   448k      0  0:00:49  0:00:23  0:00:26  399k\n",
      " 47 21.8M   47 10.4M    0     0   444k      0  0:00:50  0:00:24  0:00:26  386k\n",
      " 49 21.8M   49 10.8M    0     0   440k      0  0:00:50  0:00:25  0:00:25  341k\n",
      " 52 21.8M   52 11.4M    0     0   448k      0  0:00:49  0:00:26  0:00:23  405k\n",
      " 54 21.8M   54 11.8M    0     0   447k      0  0:00:50  0:00:27  0:00:23  413k\n",
      " 56 21.8M   56 12.2M    0     0   447k      0  0:00:50  0:00:28  0:00:22  444k\n",
      " 57 21.8M   57 12.6M    0     0   443k      0  0:00:50  0:00:29  0:00:21  437k\n",
      " 59 21.8M   59 13.0M    0     0   441k      0  0:00:50  0:00:30  0:00:20  444k\n",
      " 61 21.8M   61 13.3M    0     0   441k      0  0:00:50  0:00:31  0:00:19  403k\n",
      " 63 21.8M   63 13.8M    0     0   442k      0  0:00:50  0:00:32  0:00:18  416k\n",
      " 65 21.8M   65 14.4M    0     0   446k      0  0:00:50  0:00:33  0:00:17  439k\n",
      " 68 21.8M   68 14.9M    0     0   448k      0  0:00:49  0:00:34  0:00:15  482k\n",
      " 73 21.8M   73 16.0M    0     0   466k      0  0:00:47  0:00:35  0:00:12  621k\n",
      " 77 21.8M   77 16.9M    0     0   479k      0  0:00:46  0:00:36  0:00:10  716k\n",
      " 80 21.8M   80 17.6M    0     0   487k      0  0:00:45  0:00:37  0:00:08  772k\n",
      " 85 21.8M   85 18.7M    0     0   504k      0  0:00:44  0:00:38  0:00:06  890k\n",
      " 90 21.8M   90 19.8M    0     0   518k      0  0:00:43  0:00:39  0:00:04  995k\n",
      " 93 21.8M   93 20.5M    0     0   524k      0  0:00:42  0:00:40  0:00:02  930k\n",
      " 97 21.8M   97 21.3M    0     0   529k      0  0:00:42  0:00:41  0:00:01  881k\n",
      "100 21.8M  100 21.8M    0     0   538k      0  0:00:41  0:00:41 --:--:--  960k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o cats-and-dogs-mini-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/aleemaparakatta/cats-and-dogs-mini-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d18c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "### Creating Dataset Structure for Training and Inferencing\n",
    "\n",
    "!mkdir data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "668ab671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files to dataset\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Path to the ZIP file\n",
    "zip_path = \"cats-and-dogs-mini-dataset.zip\"\n",
    "extract_path = \"dataset\"\n",
    "\n",
    "# Open the ZIP file and extract\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(f\"Extracted files to {extract_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ba6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the 'data' directory if it doesn't exist\n",
    "data_dir = 'data'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Create the 'train' and 'test' subdirectories within 'data'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3462e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the source and destination paths\n",
    "source_cat = 'dataset/cats_set'\n",
    "dest_cat = 'dataset/cat'\n",
    "source_dog = 'dataset/dogs_set'\n",
    "dest_dog = 'dataset/dog'\n",
    "\n",
    "# Rename the directories if they exist\n",
    "if os.path.exists(source_cat):\n",
    "  os.rename(source_cat, dest_cat)\n",
    "\n",
    "if os.path.exists(source_dog):\n",
    "  os.rename(source_dog, dest_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7ec15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating the TRAIN TEST SPLIT within the DATA directory folders\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def train_test_split_folder(source_folder, train_folder, test_folder, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Splits a folder of images into training and testing sets.\n",
    "\n",
    "    Args:\n",
    "        source_folder: Path to the source folder containing subfolders for each class.\n",
    "        train_folder: Path to the folder where the training set will be saved.\n",
    "        test_folder: Path to the folder where the testing set will be saved.\n",
    "        split_ratio: The ratio of images to include in the training set (default is 0.8).\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(train_folder):\n",
    "        os.makedirs(train_folder)\n",
    "    if not os.path.exists(test_folder):\n",
    "        os.makedirs(test_folder)\n",
    "\n",
    "    for class_name in os.listdir(source_folder):\n",
    "        class_source_path = os.path.join(source_folder, class_name)\n",
    "\n",
    "        if os.path.isdir(class_source_path):  # Check if it is a directory\n",
    "            train_class_path = os.path.join(train_folder, class_name)\n",
    "            test_class_path = os.path.join(test_folder, class_name)\n",
    "\n",
    "            if not os.path.exists(train_class_path):\n",
    "                os.makedirs(train_class_path)\n",
    "            if not os.path.exists(test_class_path):\n",
    "                os.makedirs(test_class_path)\n",
    "\n",
    "            images = [f for f in os.listdir(class_source_path) if os.path.isfile(os.path.join(class_source_path, f))]\n",
    "            random.shuffle(images)\n",
    "            split_index = int(len(images) * split_ratio)\n",
    "            train_images = images[:split_index]\n",
    "            test_images = images[split_index:]\n",
    "\n",
    "            for image in train_images:\n",
    "                source_path = os.path.join(class_source_path, image)\n",
    "                destination_path = os.path.join(train_class_path, image)\n",
    "                shutil.copy(source_path, destination_path)\n",
    "\n",
    "            for image in test_images:\n",
    "                source_path = os.path.join(class_source_path, image)\n",
    "                destination_path = os.path.join(test_class_path, image)\n",
    "                shutil.copy(source_path, destination_path)\n",
    "\n",
    "\n",
    "# Example usage (assuming you have your data organized in a 'data/train' folder):\n",
    "train_test_split_folder(\"dataset\", \"data/train\", \"data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbd2c498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder data\\test\\cat count100\n",
      "Folder data\\test\\dog count100\n",
      "Folder data\\train\\cat count400\n",
      "Folder data\\train\\dog count400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_images_per_folder(root_folder):\n",
    "    \"\"\"\n",
    "    Counts the number of images in each subfolder of a given root folder.\n",
    "\n",
    "    Args:\n",
    "    root_folder: The path to the root folder.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary where keys are folder paths and values are the number of images in each folder.\n",
    "    \"\"\"\n",
    "\n",
    "    image_counts = {}\n",
    "    for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "        file = [f for f in filenames if f[-4:] in ['.jpg', '.jpeg', '.png', '.gif']]\n",
    "        \n",
    "        if len(file) > 0: \n",
    "            image_counts[dirpath] = len(file)\n",
    "    return image_counts\n",
    "\n",
    "\n",
    "image_counts = count_images_per_folder(\"data\")\n",
    "\n",
    "for folder, count in image_counts.items():\n",
    "    print(f\"Folder {folder} count{count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f72097ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many parameters - data/train\n"
     ]
    }
   ],
   "source": [
    "!tree -d data/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b400df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to train and test folders\n",
    "train_dir = \"data/train\"\n",
    "test_dir = \"data/test\"\n",
    "image_size = (128, 128)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e875e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "test_data = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610060e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # binary classification\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b338a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the Model\n",
    "checkpoint_path = 'dog_cat_cnn_model.keras'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "model.fit(\n",
    "    train_data,\n",
    "    epochs=10,\n",
    "    validation_data=test_data,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model.save('dog_cat_final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dfc680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the best saved model\n",
    "model = load_model('dog_cat_final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e2c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set parameters\n",
    "val_dir = test_dir  # same directory used for training\n",
    "image_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "# Recreate the validation generator\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.25)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Evaluate model accuracy\n",
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def predict_image(img_path, model):\n",
    "    img = image.load_img(img_path, target_size=(128, 128))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    prediction = model.predict(img_array)[0][0]\n",
    "\n",
    "    if prediction > 0.5:\n",
    "        print(\"Predicted: Dog\")\n",
    "    else:\n",
    "        print(\"Predicted: Cat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
